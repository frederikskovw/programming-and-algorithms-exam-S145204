{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will be used to get accounting entries from the bookkeeping program. Initially, the program will be used to retrieve entries from the most-used bookkeeping program in Denmark (+85% market share) - Visma E-conomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This starts by loading the environment variables from the .env file.\n",
    "# The program asserts that the environment variables are set and not placeholders.\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "app_secret_token = os.getenv('X_AppSecretToken')\n",
    "agreement_grant_token = os.getenv('X_AgreementGrantToken')\n",
    "\n",
    "assert app_secret_token is not None, \"X_AppSecretToken is missing. Please add it to your .env file.\"\n",
    "assert app_secret_token != \"ADD-APPSECRETTOKEN-HERE\", \"X_AppSecretToken is a placeholder. Please add a valid token.\"\n",
    "assert agreement_grant_token is not None, \"X_AgreementGrantToken is missing. Please add it to your .env file.\"\n",
    "assert agreement_grant_token != \"ADD-AGREEMENTGRANTTOKEN-HERE\", \"X_AgreementGrantToken is a placeholder. Please add a valid token.\"\n",
    "\n",
    "# This sets the ULR and headers for the API request.\n",
    "# The current implementation is to define the URL and headers as global variables (to simplify).\n",
    "base_url = \"https://restapi.e-conomic.com\"\n",
    "headers = {\n",
    "    'X-AppSecretToken': app_secret_token,\n",
    "    'X-AgreementGrantToken': agreement_grant_token,\n",
    "    'Content-Type': \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 308 accounts.\n",
      "Found 9 accounting years: ['2018', '2019', '2020', '2021', '2022', '2023', '2024', '2025', '2026']\n",
      "Total entries fetched: 75166\n"
     ]
    }
   ],
   "source": [
    "class EconomicAPI:\n",
    "    def __init__(self, base_url, headers, concurrency=100):\n",
    "        self.base_url = base_url\n",
    "        self.headers = headers\n",
    "        self.concurrency = concurrency\n",
    "        self.semaphore = asyncio.Semaphore(self.concurrency)\n",
    "    \n",
    "    # To retrieve this data, we need address different endpoints in the API.\n",
    "    # For each accounting entry, we need to supply the API with an account number and accounting year.\n",
    "    # Hence, or API will need to be able to retrieve a list of accounts and accounting years.\n",
    "    # Then we can use this data to retrieve the accounting entries.\n",
    "    # I'm abstracting it away in the class to simplify usage while deconstructing the API to simplify dev.\n",
    "\n",
    "    # First, I'll define a function to fetch data from the API.\n",
    "    # This function will be used to fetch data from different endpoints.\n",
    "    async def fetch_page(self, session, url, params=None):\n",
    "        async with session.get(url, headers=self.headers, params=params) as response:\n",
    "            response.raise_for_status() # This raises an exception for bad status codes (4xx, 5xx).\n",
    "            return await response.json()\n",
    "\n",
    "    # The API uses 0-based indexing for pages.\n",
    "    # So I start at page 0 and increment until there are no more pages.\n",
    "    async def fetch_pages(self, session, url):\n",
    "        all_pages = []\n",
    "        current_page_id = 1\n",
    "        params = {'pageSize': 1000} # Defaults to 1,000, the maximum number of items per page.\n",
    "        while True:\n",
    "            params['skipPages'] = current_page_id - 1\n",
    "            data = await self.fetch_page(session, url, params)\n",
    "            collection = data.get('collection', [])\n",
    "            if not collection:\n",
    "                break\n",
    "            all_pages.extend(collection)\n",
    "            current_page_id += 1\n",
    "        return all_pages\n",
    "\n",
    "    # This function retrieves the chart of accounts.\n",
    "    # The pagination and fetching logic is abstracted away in the fetch_pages function.\n",
    "    async def get_accounts(self, session):\n",
    "        url = f\"{self.base_url}/accounts\"\n",
    "        accounts_collection = await self.fetch_pages(session, url)\n",
    "        print(f\"Found {len(accounts_collection)} accounts.\")\n",
    "        return accounts_collection\n",
    "\n",
    "    # This function retrieves the accounting years.\n",
    "    async def get_accounting_years(self, session):\n",
    "        url = f\"{self.base_url}/accounting-years\"\n",
    "        years_collection = await self.fetch_pages(session, url)\n",
    "        years = [y['year'] for y in years_collection]\n",
    "        print(f\"Found {len(years)} accounting years: {years}\")\n",
    "        return years\n",
    "\n",
    "    # This function retrieves the accounting entries for a specific account and year.\n",
    "    async def get_entries(self, session, account_number, accounting_year):\n",
    "        url = f\"{self.base_url}/accounts/{account_number}/accounting-years/{accounting_year}/entries\"\n",
    "        entries_collection = await self.fetch_pages(session, url)\n",
    "        entries = []\n",
    "        for entry in entries_collection:\n",
    "            entries.append({\n",
    "                'account_number': str(account_number),\n",
    "                'amount_in_base_currency': entry.get('amountInBaseCurrency', 'N/A'),\n",
    "                'date': entry.get('date', 'N/A'),\n",
    "                'entry_number': str(entry.get('entryNumber', 'N/A')),\n",
    "                'text': str(entry.get('text', 'N/A'))\n",
    "            })\n",
    "        return entries\n",
    "\n",
    "    # I've created this wrapper which limits the number of concurrent requests and handles exceptions.\n",
    "    # E-conomic does not have a rate limit, but urge fair use of the API.\n",
    "    async def bounded_get_entries(self, session, account_number, accounting_year):\n",
    "        async with self.semaphore:\n",
    "            try:\n",
    "                return await self.get_entries(session, account_number, accounting_year)\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching entries for account {account_number}, year {accounting_year}: {e}\")\n",
    "                return None\n",
    "\n",
    "    # This is the final function that fetches all entries for all accounts and years.\n",
    "    # I'll go through it step by step\n",
    "    async def fetch_all_entries(self):\n",
    "        async with aiohttp.ClientSession() as session: # This opens a connection to the server and keeps it open for the duration of the session.\n",
    "            accounts_collection = await self.get_accounts(session) # This fetches the accounts.\n",
    "            accounting_years = await self.get_accounting_years(session) # This fetches the accounting years.\n",
    "            tasks = []\n",
    "            for account in accounts_collection:\n",
    "                for year in accounting_years: # This loops through the accounts and years to fetch the entries.\n",
    "                    tasks.append(\n",
    "                        asyncio.create_task(self.bounded_get_entries(session, account['accountNumber'], year))\n",
    "                    ) # This creates a task for each account and year, thus establishing a sort of queue to fetch multiple entries at the same time.\n",
    "            all_entries = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "            flat_entries = []\n",
    "            for result in all_entries:\n",
    "                if isinstance(result, Exception):\n",
    "                    print(f\"Task resulted in exception: {result}\")\n",
    "                elif result is not None:\n",
    "                    flat_entries.extend(result) # This takes a list of lists and turns it into a single list.\n",
    "            print(f\"Total entries fetched: {len(flat_entries)}\") # Manual debugging statement.\n",
    "            return flat_entries\n",
    "\n",
    "# Users can initialize instances of the API with different headers (the base_url, in this instance will likely not change).\n",
    "# They can use a single function to fetch all entries for all accounts and years.\n",
    "api = EconomicAPI(base_url, headers)\n",
    "entries = await api.fetch_all_entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll now write the data to an Excel file in the \"data\" directory.\n",
    "# This is done as a sort of caching mechanism to avoid fetching the data again.\n",
    "entries_df = pd.DataFrame(entries)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "file_path = f\"data/accounting_entries_{timestamp}.xlsx\"\n",
    "entries_df.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flux Analysis for month 6 has been saved to data/flux_analysis_20241215224904.xlsx.\n"
     ]
    }
   ],
   "source": [
    "# This is a very simple flux analysis that prints the difference and percentage change for the specified month.\n",
    "# You can imagine that they could add more types of analyses in the future.\n",
    "class FinancialAnalysis:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.entries_df = pd.read_excel(self.file_path)\n",
    "        self.entries_df['date'] = pd.to_datetime(self.entries_df['date'])\n",
    "\n",
    "    def analyze_flux(self, month_t):\n",
    "        entries_month_t = self.entries_df[self.entries_df['date'].dt.month == month_t]\n",
    "        entries_month_t_minus_1 = self.entries_df[self.entries_df['date'].dt.month == month_t - 1]\n",
    "        entries_month_t_grouped = entries_month_t.groupby('account_number')['amount_in_base_currency'].sum()\n",
    "        entries_month_t_minus_1_grouped = entries_month_t_minus_1.groupby('account_number')['amount_in_base_currency'].sum()\n",
    "        merged_entries = pd.merge(\n",
    "            entries_month_t_grouped, \n",
    "            entries_month_t_minus_1_grouped, \n",
    "            on='account_number', \n",
    "            how='outer', \n",
    "            suffixes=('_month_t', '_month_t_minus_1')\n",
    "        )\n",
    "        merged_entries.fillna(0, inplace=True)\n",
    "        merged_entries['difference'] = merged_entries['amount_in_base_currency_month_t'] - merged_entries['amount_in_base_currency_month_t_minus_1']\n",
    "        merged_entries['percentage_change'] = (\n",
    "            merged_entries['difference'] / merged_entries['amount_in_base_currency_month_t_minus_1']\n",
    "        ) * 100\n",
    "        merged_entries.sort_values(by='percentage_change', ascending=False, inplace=True)\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        file_path = f\"data/flux_analysis_{timestamp}.xlsx\"\n",
    "        merged_entries.to_excel(file_path)\n",
    "        print(f\"Flux Analysis for month {month_t} has been saved to {file_path}.\")\n",
    "\n",
    "# Users can initialize instances of the analysis with different accounting entries files.\n",
    "# They can use a single function to analyze the flux for a specific month.\n",
    "analysis = FinancialAnalysis(file_path)\n",
    "analysis.analyze_flux(6) # This analyzes the flux for the month of June (6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
